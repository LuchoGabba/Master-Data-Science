{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/MachineLearning/1_Introduccion/Ejercicios/regresion_ls_ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "HtxYCjX4w6t5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='#97171e'>AIT - Master in Data Science</font> 游늳\n",
        "# **Module 8: Class 4 - Regresi칩n Lineal Simple**\n",
        "\n",
        "# Prediciendo ventas de productos\n",
        "\n",
        "En este ejercicio continuaremos viendo el dataset visto en la notebook anterior. Queremos predecir las ventas del producto y nuestro conjunto de datos tiene las ventas en 200 mercados, y el presupuesto dedicado en publicidad en 3 medios: TV, radio y diario.\n",
        "\n",
        "Carguemos este dataset y algunas librer칤as:"
      ],
      "metadata": {
        "id": "nTORVO-lwqQN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilh4zsmcvsFK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns; sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/advertising.csv')"
      ],
      "metadata": {
        "id": "USR-jTAYZGcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como habiamos visto antes la relaci칩n parece ser lineal con la variable TV, es decir cuanta plata se invirti칩 ah칤. Crear un `X` dataframe que tenga solo las variables TV, Radio y Newspaper, y crear una variable `y` que tenga solo el dato de las ventas."
      ],
      "metadata": {
        "id": "kWWoHD24xfMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "X = ...\n",
        "y = ..."
      ],
      "metadata": {
        "id": "pDsTqF60xeiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1 - Train Test Split\n",
        "\n",
        "a) En este ejericio elaborar una separaci칩n de datos en entrenamiento, dejando un 25% de datos para prueba. Para eso utilicen `train_test_split` de Scikit-Learn basandose en el ejemplo presente en la [documentaci칩n](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), deber칤an crear una variable `X_train`, `X_test`, con los features, y con los targets `y_train`, e `y_test`. 쯈u칠 tama침o tiene cada conjunto? 쮼l conjunto que crearon tiene el mismo orden de filas?\n"
      ],
      "metadata": {
        "id": "_yg1LtRexl_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Completar\n",
        "..."
      ],
      "metadata": {
        "id": "k7TjRDZYyf9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Quedarse solo con la columna que corresponde a TV, y ajustar un modelo de regresion lineal al conjunto de entrenamiento con intercept. Tambien construir una matriz que tenga solo la columna de TV en el conjunto de test."
      ],
      "metadata": {
        "id": "F4xtbz8a0x5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Completar\n",
        "X_train_tv = ...\n",
        "X_test_tv  = ...\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "6wLIeb-U1ffP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Ahora vamos a querer evaluar nuestro modelo en nuestro conjunto de testeo, para eso tenemos que calcular las predicciones del modelo $\\hat{y}$, y para esto usamos el m칠todo `predict` sobre todo el conjunto de testeo.\n",
        "\n",
        "`y_predicted = modelo.predict(X_test)`\n",
        "\n",
        "Luego, usando los valores reales de `y` en el conjunto de test, nos interesa calcular el error de nuestro modelo en datos que no vio, justamente el conjunto de test. Para eso vamos a calcular uno de los errores m치s populares, el [Error Cuadr치tico Medio](https://es.wikipedia.org/wiki/Error_cuadr%C3%A1tico_medio):\n",
        "\n",
        "$ ECM = \\dfrac{1}{n} \\sum (y_i - \\hat{y}_i)^2$\n",
        "\n",
        "Es decir que el ECM es el promedio de la diferencia entre los vectores `y_test` e `y_predict` elevadas al cuadrado. Calcular el ECM usando solo herramientas de `numpy`:"
      ],
      "metadata": {
        "id": "I6epDgvv1qF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "\n",
        "# calculamos las predicciones sobre test\n",
        "y_predict = ...\n",
        "\n",
        "# calculamos el cuadrado de las diferencias de estos vectores\n",
        "ecm = ...\n",
        "\n",
        "# calculamos el promedio usando mean\n",
        "print('El ECM fue de: ', ecm.mean())"
      ],
      "metadata": {
        "id": "r7qpBxyX1quB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Podemos usar el ECM que nos brinda SkLearn: [RMS](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=rms). Calcularlo el ECM para cada conjunto, entrenamiento y testo. 쮼n que conjunto rindi칩 mejor nuestro modelo?"
      ],
      "metadata": {
        "id": "GIbJK_Ka29hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Completar (deber칤a dar lo mismo que el item anterior)\n",
        "..."
      ],
      "metadata": {
        "id": "E0HV-ZiH7I04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2 - Probando otras variables\n",
        "\n",
        "Ajustar un modelo lineal para cada variable sobre el conjunto que entrenamiento y calcular el error sobre cada conjunto para cada modelo. Comparar el rendimiento de cada modelo en ambos conjuntos, 쯖u치l fue el mejor modelo?. Por lo visto en clase, 쯘ra esperable este resultado?"
      ],
      "metadata": {
        "id": "rLhkpva20gBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Completar\n",
        "\n",
        "# sugerencia (pueden no usarla)\n",
        "def regresion_ls(X_train:pd.DataFrame,\n",
        "                 X_test :pd.DataFrame,\n",
        "                 y_train:pd.Series,\n",
        "                 y_test :pd.Series,\n",
        "                 var: str):\n",
        "  \"\"\"\n",
        "  Input\n",
        "    X, y: Datos\n",
        "    var: Nombre del feature a utilizar para ajustar un modelo de regresion simple\n",
        "  Output\n",
        "    El modelo y m칠trica\n",
        "  \"\"\"\n",
        "  ...\n",
        "\n",
        "  return modelo\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "hMsoUOCJ601-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "쮺u치l es el peso asignado a cada variable por nuestros modelos? 쯋tilizar칤a solo este dato para hacer una recomendaci칩n sobre donde invertir de los tres medios?"
      ],
      "metadata": {
        "id": "AM2gOKfd9JKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "..."
      ],
      "metadata": {
        "id": "Wn1mBdUA9G5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Haciendo regresiones en conjuntos de juguete\n",
        "\n",
        "Scikit-Learn es una librer칤a muy vers치til que nos brinda herramientas no solo relacionados a los tipos de modelos, sino que tamb칤en nos deja crear datasets de juguete seg칰n la tarea que nos interese, en este caso la regresi칩n. Para eso contamos con la funci칩n [`make_regresion`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression), donde no solo obtenemos las features y los targets, sino que tambi칠n nos devuelve el coeficiente utilizado para generar este conjunto."
      ],
      "metadata": {
        "id": "mTz1eJgw2n8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ejemplo\n",
        "n_samples_train, n_samples_test, n_features = 4000, 1000, 1\n",
        "\n",
        "X, y, coef = make_regression(\n",
        "    n_samples=n_samples_train + n_samples_test,\n",
        "    n_features=n_features,\n",
        "    n_informative=1,\n",
        "    shuffle=False,\n",
        "    noise=10.0,\n",
        "    coef=True,\n",
        "    bias = -7,\n",
        "    random_state = 2022\n",
        ")\n",
        "\n",
        "plt.scatter(X,y);\n",
        "print(coef)"
      ],
      "metadata": {
        "id": "19bqwWBrA8vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos crea un dataset donde con la cantidad de muestras solicitadas, la cantidad de features, pudiendo controlar el ruido que se utiliza para generar estas instancias. Vamos a utilizar este dataset para evaluar nuestros modelos de regresi칩n, aprovechando que sabemos el *coeficiente* que se utiliz칩 para generar los datos."
      ],
      "metadata": {
        "id": "pF8SSslTPb1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1 - Toy Dataset\n",
        "\n",
        "A partir del X e y creados anteriormente, seleccione los 칰ltimos 1000 datos para el conjunto de testeo y los primeros 4000 para entrenamiento. Ajuste un modelo lineal con intercept y reporte el *error cuadr치tico* tanto en entrenamiento como en test. Reporten el error cuadr치tico en test."
      ],
      "metadata": {
        "id": "1QWS1iuC75Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "X_train = ...\n",
        "y_train = ...\n",
        "X_test = ...\n",
        "y_test = ...\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "PuFRMyfH745h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "쯈u칠 tan parecidos quedaron los coeficientes de nuestro modelo en comparaci칩n de los que se usaron para generar nuestro dataset?"
      ],
      "metadata": {
        "id": "GUBpLmcIYXm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "..."
      ],
      "metadata": {
        "id": "aWS93JkPYIe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar los datos junto a nuestro modelo."
      ],
      "metadata": {
        "id": "7XHUMrOoYmgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar\n",
        "\n",
        "# para graficar la recta\n",
        "xfit = np.linspace(-4, 4, 1000)\n",
        "yfit = ...\n",
        "\n",
        "plt.scatter(X_train, y_train, label = 'train')\n",
        "plt.scatter(X_test, y_test, label = 'test')\n",
        "plt.plot(xfit, yfit, 'r', label = 'modelo');\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "6tP5nZKAYmLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2 - Comparando nuestros modelos con $R^2$\n",
        "\n",
        "$R^2$ es una m칠trica que nos permite evaluar cuanta variabilidad del conjunto original de datos camptura nuestro modelo. Se lo conoce tambi칠n como el [*coeficiente de determinaci칩n*](https://es.wikipedia.org/wiki/Coeficiente_de_determinaci%C3%B3n), y sklearn tiene su [implementaci칩n](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html?highlight=r2#sklearn.metrics.r2_score). A diferencia del ECM, no se trata de una funci칩n de error, que mide que tan lejos esta nuestro modelo de los datos reales (errores m치s chicos es mejor), sino de un *score* o puntaje, es decir que m치s grande es mejor y lo m치ximo que pude valer es 1.\n",
        "\n",
        "$ R^2 = 1 - \\frac{\\text{variaci칩n no explicada}}{\\text{variaci칩n total}} = 1 - \\dfrac{(\\sum y_i - \\hat{y}_i)^2}{(\\sum y_i - \\bar{y})^2}$\n",
        "\n",
        "\n",
        "Calcular el valor de $R^2$ para nuestro modelo:"
      ],
      "metadata": {
        "id": "p8CKHtzW0oAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Completar\n",
        "r2 = ...\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "KeFCAfFT1LGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3 - Efecto del conjunto de entrenamiento: Learning Curves\n",
        "\n",
        "Muchas veces escucharemos aseverar que tener m치s datos es mejor, pero eso no es necesariamente cierto. Para ver si nuestro modelo necesita mas datos para mejorar su rendimiento podemos armar lo que se conoce como *curvas de aprendizaje* o *Learning curves*.\n",
        "\n",
        "B치sicamente lo que haremos es empezar de un conjunto de entrenamiento muy peque침o e iremos incrementando la cantidad de datos del mismo, para ver si el rendimiento de cada modelo mejor o no al incorporar m치s datos. Scikit Learn nos provee una [funci칩n](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve) para hacerlo, sin embargo vamos a hacer algo similar pero de manera manual.\n",
        "\n",
        "Completar el c칩digo siguiente para calcular un modelo para cada subconjunto de entrenamiento considerado, en el cual nos iremos quedando con distintos porcentajes de entrenamiento desde el 5% al 100%. Guardarse los $R^2$ en entrenamiento y testeo para cada modelo y finalmente realizar un gr치fico donde veamos el error en funci칩n del porcentaje total de datos usado."
      ],
      "metadata": {
        "id": "5DoQn-R38Cbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Completar -\n",
        "\n",
        "train_errs = []\n",
        "test_errs  = []\n",
        "\n",
        "...\n",
        "\n",
        "plt.plot(np.linspace(0.05,1,20), train_errs)\n",
        "plt.plot(np.linspace(0.05,1,20), test_errs)\n",
        "plt.legend(['train', 'test']);"
      ],
      "metadata": {
        "id": "tQRHyAt28BrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos finalmente que nuestro modelo mejora con m치s datos de entrenamiento su rendimiento en entrenamiento, como era esperable. Sin embargo, satura rapidamente el rendimiento en test.\n",
        "\n",
        "*Aclaraci칩n*: Lo que acabamos de hacer no es exactamente una curva de aprendizaje, ya que deberiamos, para cada percentil, poder ajustar muchos conjuntos aleatorio con esa cantida de casos. Esto al menos nos garantizar치 poder estimar los desv칤os para poder tener mayor rigurosidad estad칤stica.\n",
        "\n",
        "Para m치s detalles analizar este [ejemplo](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)."
      ],
      "metadata": {
        "id": "9KmQ8tyIWFxg"
      }
    }
  ]
}